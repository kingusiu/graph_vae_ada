{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import models.graph_nn as grap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(particles):\n",
    "    idx_pt, idx_eta, idx_phi, idx_class = range(4)\n",
    "    # min-max normalize pt\n",
    "    particles[:,:,idx_pt] = (particles[:,:,idx_pt] - np.min(particles[:,:,idx_pt])) / (np.max(particles[:,:,idx_pt])-np.min(particles[:,:,idx_pt]))\n",
    "    # standard normalize angles\n",
    "    particles[:,:,idx_eta] = (particles[:,:,idx_eta] - np.mean(particles[:,:,idx_eta]))/np.std(particles[:,:,idx_eta])\n",
    "    particles[:,:,idx_eta] = (particles[:,:,idx_eta] - np.mean(particles[:,:,idx_phi]))/np.std(particles[:,:,idx_phi])\n",
    "    # min-max normalize class label\n",
    "    particles[:,:,idx_class] = (particles[:,:,idx_class] - np.min(particles[:,:,idx_class])) / (np.max(particles[:,:,idx_class])-np.min(particles[:,:,idx_class]))\n",
    "    return particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_adjacency(A):\n",
    "    D = np.array(np.sum(A, axis=2), dtype=np.float32) # compute outdegree (= rowsum)\n",
    "    D = np.nan_to_num(np.power(D,-0.5), posinf=0, neginf=0) # normalize (**-(1/2))\n",
    "    D = np.asarray([np.diagflat(dd) for dd in D]) # and diagonalize\n",
    "    return np.matmul(D, np.matmul(A, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_adjacencies(particles):\n",
    "    real_p_mask = particles[:,:,0] > 0\n",
    "    adjacencies = (real_p_mask[:,:,np.newaxis] * real_p_mask[:,np.newaxis,:]).astype('int')\n",
    "    return adjacencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/kinga/dev/datasamples/L1_anomaly_challenge/background_training_1M.h5'\n",
    "ff = h5py.File(filename, 'r')\n",
    "particles = np.asarray(ff.get('Particles'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 19, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_n = particles.shape[1]\n",
    "feat_sz = particles.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: array([b'Pt', b'Eta', b'Phi', b'Class'], dtype='|S5')\n",
    "particles_train = particles[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinga/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "A = make_adjacencies(particles_train)\n",
    "A_tilde = normalized_adjacency(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(particles_train[:,:,0].flatten())\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_train = normalize_features(particles_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'normalized pt')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQpklEQVR4nO3de7BdZXnH8e9PIjiCYofgVCHxYBPQVOulp6DTadVqnQBGnKqYVFqxGTJgcTrtODVecOzFijOtMzKl1XTEWGfkou3YpMTipSJTB5SAtwBFI8YmXEwERa0XiD79Yy+c3UOSs5O999nnvPl+Zs5k77XWXut5z+WXdZ79nrVSVUiS2vKISRcgSRo9w12SGmS4S1KDDHdJapDhLkkNMtwlqUGGu7QfSSrJsu7xe5NcNOL9n5vkv0a5T+khiyZdgLQQVNX5k66hX5K3A8uq6pxJ16L5yTN3NSGJJypSH8NdE5VkR5I3JPlKkvuTXJnkUX3rz0uyPcl9STYleWLfukryx0m+Dnw9yfOT7Ery50l2J7k7ycuSnJHka90+3tz3+lOTXJ/ke922f5/kyP3UuTHJX3ePNyf5Yd/Hz5Oc2617SpJPdse6PcnZffs4rhvD95N8AfiVA3xeprrxrUtyV1ffG7p1K4E3A6/qjv/lQ/z0q2GGu+aDs4GVwEnArwHnAiT5HeCd3fonAN8Crpjx2pcBpwEruue/DDwKOAF4G/BPwDnArwO/BVyU5KRu258BfwosBp4LvBB43WzFVtWqqjqmqo4BXgncA3w6ydHAJ4EPA48HVgP/kOSh2i4FftKN5Y+6j9m8AFgOvBh4Y5IXVdV/AH8DXNnV8YwB9qPDjOGu+eCSqrqrqu4DNgPP7Ja/Grisqm6uqp8CbwKem2Sq77XvrKr7qurH3fMHgXdU1YP0/iNYDLynqn5QVbcAtwLPAKiqm6rqhqraW1U7gPcBzxu06CQnAx8Ezq6qncBLgB1V9YFun18E/gV4ZZIjgJcDb6uq/62qbd1rZ/MX3fZfBT4ArBm0Ph3e7FNqPrin7/GPgIdaL08Ebn5oRVX9MMm99M7Kd3SLd87Y171V9bPu8UOB/+2+9T8GjoFfhPO7gWng0fR+Hm4apOAkxwL/Bry1qh6a8fIk4LQk3+vbdBHwIeD47nF/vd8a4FAzt3/6IPVJnrlrPruLXmAC0LU9jgPu7NtmmMua/iPw38DyqnosvT52ZntRkkfQa718pqo29K3aCXy2qh7X93FMVV0A7AH2Akv6tl86QI0zt7+re+zlXHVAhrvms8uB1yZ5ZpKj6PWZP9+1UEbhMcD3gR8meQpwwYCvewdwNPAnM5b/O3Bykj9I8sju4zeSPLX7beJfgbcneXTXh3/NAMe6qNv+V4HXAld2y78NTHX/0UgP4zeG5q2q+hRwEb2+9d30ZpesHuEh3gD8PvADem+8XnngzX9hDfAc4Lt9M2ZeXVU/oPfG52p6Z9j3AO8CjupedyG9ltA9wEZ6PfTZfBbYDnwa+Nuq+kS3/CPdv/cmuXmfr9RhLd6sQ5p/ujeNvwk8sqr2TrgcLUCeuUtSgwx3SWqQbRlJapBn7pLUoHnxR0yLFy+uqampSZchSQvKTTfd9J2qOn5f6+ZFuE9NTbF169ZJlyFJC0qS/f6V80TbMklWJdlw//33T7IMSWrORMO9qjZX1bpjjz12kmVIUnN8Q1WSGmRbRpIaZFtGkhpkW0aSGmRbRpIaZFtGkho0L/6IaRhT66+e2LF3XHzmxI4tSQdiW0aSGmRbRpIa5GwZSWqQ4S5JDbLnLkkNsucuSQ2yLSNJDTLcJalBhrskNchwl6QGOVtGkhrkbBlJapBtGUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQg57lLUoOc5y5JDbItI0kNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQWMI9ydFJtiZ5yTj2L0k6sIHCPcllSXYn2TZj+coktyfZnmR936o3AleNslBJ0uAGPXPfCKzsX5DkCOBS4HRgBbAmyYokvwvcCuweYZ2SpIOwaJCNquq6JFMzFp8KbK+qOwCSXAGcBRwDHE0v8H+cZEtV/XzmPpOsA9YBLF269JAHIEl6uIHCfT9OAHb2Pd8FnFZVFwIkORf4zr6CHaCqNgAbAKanp2uIOiRJMwwT7gdUVRtn2ybJKmDVsmXLxlWGJB2WhpktcyewpO/5id2ygXnJX0kaj2HC/UZgeZKTkhwJrAY2jaYsSdIwBp0KeTlwPXBKkl1J1lbVXuBC4BrgNuCqqrrlYA7unZgkaTwGnS2zZj/LtwBbDvXgVbUZ2Dw9PX3eoe5DkvRw3kNVkhrkPVQlqUFeOEySGmRbRpIaZFtGkhpkW0aSGmS4S1KD7LlLUoPsuUtSg2zLSFKDDHdJatDYruc+iIV+Pfep9VdP5Lg7Lj5zIseVtHDYc5ekBtmWkaQGGe6S1CDDXZIaZLhLUoP8C1VJapCzZSSpQbZlJKlBhrskNchwl6QGGe6S1CDDXZIaZLhLUoOc5y5JDXKeuyQ1yLaMJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUEjD/ckT03y3iQfTXLBqPcvSZrdQOGe5LIku5Nsm7F8ZZLbk2xPsh6gqm6rqvOBs4HfHH3JkqTZDHrmvhFY2b8gyRHApcDpwApgTZIV3bqXAlcDW0ZWqSRpYAOFe1VdB9w3Y/GpwPaquqOqHgCuAM7qtt9UVacDr97fPpOsS7I1ydY9e/YcWvWSpH1aNMRrTwB29j3fBZyW5PnA7wFHcYAz96raAGwAmJ6eriHqkCTNMEy471NVXQtcO8i2SVYBq5YtWzbqMiTpsDbMbJk7gSV9z0/slg3MS/5K0ngME+43AsuTnJTkSGA1sOlgduDNOiRpPAadCnk5cD1wSpJdSdZW1V7gQuAa4Dbgqqq65WAO7pm7JI3HQD33qlqzn+VbcLqjJM073kNVkhrkPVQlqUFeOEySGmRbRpIaNPI/YjoYVbUZ2Dw9PX3eJOtYaKbWXz2xY++4+MyJHVvS4GzLSFKDDHdJapA9d0lqkFMhJalBtmUkqUGGuyQ1yJ67JDXInrskNci2jCQ1yHCXpAYZ7pLUIMNdkhrkbBlJapCzZSSpQbZlJKlBhrskNchwl6QGGe6S1CDDXZIa5FRISWqQUyElqUG2ZSSpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGLxrHTJC8DzgQeC7y/qj4xjuNIkvZt4DP3JJcl2Z1k24zlK5PcnmR7kvUAVfWxqjoPOB941WhLliTN5mDaMhuBlf0LkhwBXAqcDqwA1iRZ0bfJW7v1kqQ5NHC4V9V1wH0zFp8KbK+qO6rqAeAK4Kz0vAv4eFXdvK/9JVmXZGuSrXv27DnU+iVJ+zDsG6onADv7nu/qlr0eeBHwiiTn7+uFVbWhqqaravr4448fsgxJUr+xvKFaVZcAl8y2XZJVwKply5aNowyNwdT6qydy3B0XnzmR40oL1bBn7ncCS/qen9gtG4jXc5ek8Rg23G8Elic5KcmRwGpg06Av9k5MkjQeBzMV8nLgeuCUJLuSrK2qvcCFwDXAbcBVVXXLoPv0zF2SxmPgnntVrdnP8i3AlpFVJEkamjfIlqQGeYNsSWqQFw6TpAbZlpGkBtmWkaQG2ZaRpAbZlpGkBtmWkaQG2ZaRpAYZ7pLUIMNdkhrkG6qS1CDfUJWkBtmWkaQGGe6S1CDDXZIa5BuqktQg31CVpAYNfJs9aZKm1l89kePuuPjMiRxXGpY9d0lqkOEuSQ0y3CWpQYa7JDXIcJekBjnPXZIa5Dx3SWqQbRlJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg0Ye7kmenOT9ST466n1LkgYzULgnuSzJ7iTbZixfmeT2JNuTrAeoqjuqau04ipUkDWbQM/eNwMr+BUmOAC4FTgdWAGuSrBhpdZKkQzJQuFfVdcB9MxafCmzvztQfAK4AzhpxfZKkQzDMPVRPAHb2Pd8FnJbkOOAdwLOSvKmq3rmvFydZB6wDWLp06RBlSOMzqXu3gvdv1XBGfoPsqroXOH+A7TYAGwCmp6dr1HVI0uFsmNkydwJL+p6f2C0bmNdzl6TxGCbcbwSWJzkpyZHAamDTwezA67lL0ngMOhXycuB64JQku5Ksraq9wIXANcBtwFVVdcvBHNwzd0kaj4F67lW1Zj/LtwBbDvXgVbUZ2Dw9PX3eoe5DkvRwXn5AkhrkDbIlqUHeIFuSGmRbRpIaZFtGkhpkW0aSGmRbRpIaNPJryxyMJKuAVcuWLZtkGdK8NKmLlnnBsjbYlpGkBtmWkaQGGe6S1CCnQkpSg+y5S1KDbMtIUoMMd0lqkOEuSQ0y3CWpQc6WkaQGOVtGkhpkW0aSGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yDsxSfp/JnUHqMPVuO585Tx3SWqQbRlJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg1JVk66BJHuAbx3iyxcD3xlhOQuBYz48OObDwzBjflJVHb+vFfMi3IeRZGtVTU+6jrnkmA8PjvnwMK4x25aRpAYZ7pLUoBbCfcOkC5gAx3x4cMyHh7GMecH33CVJD9fCmbskaQbDXZIatGDCPcnKJLcn2Z5k/T7WH5Xkym7955NMTaDMkRpgzH+W5NYkX0ny6SRPmkSdozTbmPu2e3mSSrLgp80NMuYkZ3df61uSfHiuaxy1Ab63lyb5TJIvdt/fZ0yizlFJclmS3Um27Wd9klzSfT6+kuTZQx+0qub9B3AE8A3gycCRwJeBFTO2eR3w3u7xauDKSdc9B2N+AfDo7vEFh8OYu+0eA1wH3ABMT7ruOfg6Lwe+CPxS9/zxk657Dsa8Abige7wC2DHpuocc828Dzwa27Wf9GcDHgQDPAT4/7DEXypn7qcD2qrqjqh4ArgDOmrHNWcAHu8cfBV6YJHNY46jNOuaq+kxV/ah7egNw4hzXOGqDfJ0B/gp4F/CTuSxuTAYZ83nApVX1XYCq2j3HNY7aIGMu4LHd42OBu+awvpGrquuA+w6wyVnAP1fPDcDjkjxhmGMulHA/AdjZ93xXt2yf21TVXuB+4Lg5qW48Bhlzv7X0/udfyGYdc/fr6pKqauUuzoN8nU8GTk7yuSQ3JFk5Z9WNxyBjfjtwTpJdwBbg9XNT2sQc7M/7rBYNVY7mhSTnANPA8yZdyzgleQTwbuDcCZcy1xbRa808n95vZ9cleXpVfW+SRY3ZGmBjVf1dkucCH0rytKr6+aQLWygWypn7ncCSvucndsv2uU2SRfR+lbt3Tqobj0HGTJIXAW8BXlpVP52j2sZltjE/BngacG2SHfR6k5sW+Juqg3yddwGbqurBqvom8DV6Yb9QDTLmtcBVAFV1PfAoehfYatVAP+8HY6GE+43A8iQnJTmS3humm2Zsswl4Tff4FcB/VvdOxQI165iTPAt4H71gX+h9WJhlzFV1f1Utrqqpqpqi9z7DS6tq62TKHYlBvrc/Ru+snSSL6bVp7pjDGkdtkDH/D/BCgCRPpRfue+a0yrm1CfjDbtbMc4D7q+ruofY46XeRD+Ld5jPonbF8A3hLt+wv6f1wQ++L/xFgO/AF4MmTrnkOxvwp4NvAl7qPTZOuedxjnrHttSzw2TIDfp1Drx11K/BVYPWka56DMa8APkdvJs2XgBdPuuYhx3s5cDfwIL3fxNYC5wPn932NL+0+H18dxfe1lx+QpAYtlLaMJOkgGO6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQf8HVO3zghLkfjwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(particles_train[:,:,0].flatten())\n",
    "plt.yscale('log')\n",
    "plt.title('normalized pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model: Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_features (InputLa [(None, 19, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_adjacency (InputL [(None, 19, 19)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_3 (GraphConvo (None, 19, 3)        12          encoder_input_features[0][0]     \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_4 (GraphConvo (None, 19, 2)        6           graph_convolution_3[0][0]        \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_5 (GraphConvo (None, 19, 1)        2           graph_convolution_4[0][0]        \n",
      "                                                                 encoder_input_adjacency[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gnn = grap.GraphAutoencoder(nodes_n=nodes_n, feat_sz=feat_sz, activation=tf.nn.tanh)\n",
    "gnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 23ms/step - val_loss: 0.6810\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 18ms/step - val_loss: 0.6797\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6794\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6793\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6792\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6792\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6792\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 16ms/step - val_loss: 0.6791\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6791\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 20ms/step - val_loss: 0.6791\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6790\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 16ms/step - val_loss: 0.6790\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 16ms/step - val_loss: 0.6790\n",
      "Epoch 14/100\n",
      "16/18 [=========================>....] - ETA: 0s\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6790\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6790\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 18ms/step - val_loss: 0.6790\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 16ms/step - val_loss: 0.6790\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 16ms/step - val_loss: 0.6790\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 25ms/step - val_loss: 0.6790\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6790\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 16ms/step - val_loss: 0.6790\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 18ms/step - val_loss: 0.6790\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 18ms/step - val_loss: 0.6790\n",
      "Epoch 24/100\n",
      "15/18 [========================>.....] - ETA: 0s\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6790\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6790\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6790\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 24ms/step - val_loss: 0.6789\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 16ms/step - val_loss: 0.6790\n",
      "Epoch 29/100\n",
      "17/18 [===========================>..] - ETA: 0s\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "18/18 [==============================] - 0s 16ms/step - val_loss: 0.6790\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6790\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6790\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 1s 43ms/step - val_loss: 0.6790\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 34/100\n",
      "15/18 [========================>.....] - ETA: 0s\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "18/18 [==============================] - 0s 20ms/step - val_loss: 0.6789\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 25ms/step - val_loss: 0.6789\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 16ms/step - val_loss: 0.6789\n",
      "Epoch 39/100\n",
      "17/18 [===========================>..] - ETA: 0s\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 19ms/step - val_loss: 0.6789\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - ETA: 0s\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 49/100\n",
      "17/18 [===========================>..] - ETA: 0s\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 23ms/step - val_loss: 0.6789\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6789\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 24ms/step - val_loss: 0.6789\n",
      "Epoch 54/100\n",
      "15/18 [========================>.....] - ETA: 0s\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6789\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6789\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 23ms/step - val_loss: 0.6789\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 18ms/step - val_loss: 0.6789\n",
      "Epoch 59/100\n",
      "16/18 [=========================>....] - ETA: 0s\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "18/18 [==============================] - 0s 23ms/step - val_loss: 0.6789\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 64/100\n",
      "17/18 [===========================>..] - ETA: 0s\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6789\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 19ms/step - val_loss: 0.6789\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 19ms/step - val_loss: 0.6789\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 20ms/step - val_loss: 0.6789\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 18ms/step - val_loss: 0.6789\n",
      "Epoch 69/100\n",
      "16/18 [=========================>....] - ETA: 0s\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 23ms/step - val_loss: 0.6789\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 74/100\n",
      "17/18 [===========================>..] - ETA: 0s\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 16ms/step - val_loss: 0.6789\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6789\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 79/100\n",
      "16/18 [=========================>....] - ETA: 0s\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.220703097715159e-06.\n",
      "18/18 [==============================] - 0s 20ms/step - val_loss: 0.6789\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6789\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 24ms/step - val_loss: 0.6789\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 23ms/step - val_loss: 0.6789\n",
      "Epoch 84/100\n",
      "15/18 [========================>.....] - ETA: 0s\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 6.103515488575795e-07.\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 18ms/step - val_loss: 0.6789\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6789\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 89/100\n",
      "16/18 [=========================>....] - ETA: 0s\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 3.0517577442878974e-07.\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6789\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - ETA: 0s\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.5258788721439487e-07.\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6789\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 21ms/step - val_loss: 0.6789\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 17ms/step - val_loss: 0.6789\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 18ms/step - val_loss: 0.6789\n",
      "Epoch 99/100\n",
      "17/18 [===========================>..] - ETA: 0s\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 7.629394360719743e-08.\n",
      "18/18 [==============================] - 0s 20ms/step - val_loss: 0.6789\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 22ms/step - val_loss: 0.6789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0bf83befd0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5, verbose=1)]\n",
    "gnn.fit((particles_train, A_tilde), A, epochs=100, batch_size=128, validation_split=0.25, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinga/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "particles_test = particles[2000:3000]\n",
    "A_test = make_adjacencies(particles_test)\n",
    "A_tilde_test = normalized_adjacency(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer graph_autoencoder_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z, A_pred_probs = gnn((particles_test, A_tilde_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pred = (A_pred_probs > 0.5).numpy().astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_background = gnn.test_step(((particles_test, A_tilde_test), A_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.68007964>}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and predict signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/kinga/dev/datasamples/L1_anomaly_challenge/hToTauTau_13TeV_PU20.h5'\n",
    "ff = h5py.File(filename, 'r')\n",
    "particles_signal = np.asarray(ff.get('Particles'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691283, 19, 4)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particles_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: array([b'Pt', b'Eta', b'Phi', b'Class'], dtype='|S5')\n",
    "particles_signal_test = particles_signal[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinga/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "A_signal = make_adjacencies(particles_signal_test)\n",
    "A_tilde_signal = normalized_adjacency(A_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPPUlEQVR4nO3db4wcd33H8fenNg5gaALEQqmdcI4ucusHFUSnAAIh1EJrE5xUFLW2kAqVGyu0qUr7oHXUqhLPQlVVLVJKapU0VUUd3JRSJzEKlD+KVEUhFwhgYwzXYIgjwAZEkFClEPj2wY7J9eJz9m53PXu/vF/SyTO/3dv5+Hbue3PfmZtfqgpJUlt+ru8AkqTxs7hLUoMs7pLUIIu7JDXI4i5JDVrfdwCASy+9tGZmZvqOIUlrysMPP/zdqtp0rsd6Le5JdgG7ZmdnmZ+f7zOKJK05Sb6x3GO9tmWq6u6q2nfxxRf3GUOSmtNrcU+yK8mBJ554os8YktQcj9wlqUFeLSNJDbItI0kNsi0jSQ2yLSNJDbItI0kN6vWPmKrqbuDuubm5G1b7GjP77x1jopU5ecu1vW1bks7HtowkNci2jCQ1yKtlJKlBtmUkqUEWd0lqkD13SWqQPXdJapBtGUlqkMVdkhpkcZekBnlCVZIa5AlVSWqQbRlJapDFXZIaZHGXpAZZ3CWpQRZ3SWqQxV2SGuR17pLUIK9zl6QG2ZaRpAZZ3CWpQRZ3SWqQxV2SGmRxl6QGWdwlqUEWd0lq0ESKe5KNSeaTvHUSry9JOr+hinuS25OcTnJ0yfiOJCeSLCTZv+ihPwMOjTOoJGl4wx653wHsWDyQZB1wK7AT2A7sSbI9yZuBLwOnx5hTkrQC64d5UlXdn2RmyfA1wEJVPQqQ5E7geuBFwEYGBf9/kxypqp8ufc0k+4B9AFdcccWq/wOSpGcaqrgvYzPw2KL1U8Crq+omgCTvAr57rsIOUFUHgAMAc3NzNUIOSdISoxT386qqO57tOUl2AbtmZ2cnFUOSnpNGuVrmceDyRetburGheVdISZqMUYr7Q8BVSbYm2QDsBg6v5AW8n7skTcawl0IeBB4AtiU5lWRvVT0F3ATcBxwHDlXVsZVs3CN3SZqMYa+W2bPM+BHgyFgTSZJG5jR7ktQgp9mTpAZ55C5JDfLIXZIa5C1/JalBFndJapA9d0lqkD13SWqQbRlJapDFXZIaZM9dkhpkz12SGmRbRpIaZHGXpAZZ3CWpQZ5QlaQGeUJVkhpkW0aSGmRxl6QGWdwlqUEWd0lqkMVdkhrkpZCS1CAvhZSkBtmWkaQGre87wFo2s//eXrZ78pZre9mupLXDI3dJapDFXZIaZHGXpAZZ3CWpQRZ3SWqQxV2SGjT24p7kl5LcluSuJO8e9+tLkp7dUMU9ye1JTic5umR8R5ITSRaS7AeoquNVdSPwW8Drxh9ZkvRshj1yvwPYsXggyTrgVmAnsB3Yk2R799h1wL3AkbEllSQNbajiXlX3A99fMnwNsFBVj1bVk8CdwPXd8w9X1U7gHcu9ZpJ9SeaTzJ85c2Z16SVJ5zTK7Qc2A48tWj8FvDrJG4G3ARdxniP3qjoAHACYm5urEXJIkpYY+71lquozwGeGeW6SXcCu2dnZcceQpOe0Ua6WeRy4fNH6lm5saN7yV5ImY5Ti/hBwVZKtSTYAu4HDK3kBJ+uQpMkY9lLIg8ADwLYkp5LsraqngJuA+4DjwKGqOraSjXvkLkmTMVTPvar2LDN+hBEud7TnLkmT4TR7ktQg7y0jSQ3qtbh7QlWSJsO2jCQ1yLaMJDXItowkNci2jCQ1yLaMJDXI4i5JDbLnLkkNsucuSQ2yLSNJDbK4S1KDLO6S1CCLuyQ1aOxzqK6E93NfnZn99/a27ZO3XNvbtiUNz6tlJKlBtmUkqUEWd0lqkMVdkhpkcZekBlncJalB3jhMkhrkpZCS1CDbMpLUIIu7JDXI4i5JDbK4S1KDLO6S1CCLuyQ1yOIuSQ2ayP3ck/wGcC3w88AHq+rjk9iOJOnchj5yT3J7ktNJji4Z35HkRJKFJPsBquqjVXUDcCPw2+ONLEl6Nitpy9wB7Fg8kGQdcCuwE9gO7EmyfdFT/qJ7XJJ0AQ1d3KvqfuD7S4avARaq6tGqehK4E7g+A+8DPlZVnzvX6yXZl2Q+yfyZM2dWm1+SdA6jnlDdDDy2aP1UN/aHwJuAtye58VyfWFUHqmququY2bdo0YgxJ0mITOaFaVe8H3v9sz3OC7LWnr8m5nZhbWplRj9wfBy5ftL6lGxuKd4WUpMkYtbg/BFyVZGuSDcBu4PDosSRJo1jJpZAHgQeAbUlOJdlbVU8BNwH3AceBQ1V1bAWv6WQdkjQBQ/fcq2rPMuNHgCOr2XhV3Q3cPTc3d8NqPl+SdG5OsydJDXKaPUlqkDcOk6QG2ZaRpAbZlpGkBtmWkaQG2ZaRpAbZlpGkBtmWkaQGWdwlqUH23CWpQfbcJalBtmUkqUEWd0lqkMVdkhrkCVVJapAnVCWpQbZlJKlBFndJatDQc6hKfZrZf28v2z15y7W9bFcalUfuktQgi7skNcjiLkkN8jp3SWqQ17lLUoNsy0hSgyzuktQgi7skNcjiLkkNsrhLUoMs7pLUIIu7JDVo7MU9yZVJPpjkrnG/tiRpOEMV9yS3Jzmd5OiS8R1JTiRZSLIfoKoeraq9kwgrSRrOsEfudwA7Fg8kWQfcCuwEtgN7kmwfazpJ0qoMVdyr6n7g+0uGrwEWuiP1J4E7geuH3XCSfUnmk8yfOXNm6MCSpGc3Ss99M/DYovVTwOYkL0tyG/CqJDcv98lVdaCq5qpqbtOmTSPEkCQtNfaZmKrqe8CNwzw3yS5g1+zs7LhjSGPR1wxQ4CxQGs0oR+6PA5cvWt/SjQ3Nu0JK0mSMUtwfAq5KsjXJBmA3cHglL+D93CVpMoa9FPIg8ACwLcmpJHur6ingJuA+4DhwqKqOrWTjHrlL0mQM1XOvqj3LjB8Bjow1kSRpZGM/oboSnlCVpo8nkdvgNHuS1CAnyJakBnnkLkkN8pa/ktQgi7skNcieuyQ1yJ67JDXItowkNcjiLkkN8i9UJT3ntfhXufbcJalBtmUkqUEWd0lqkMVdkhrkHzFJUoM8oSpJDbItI0kNsrhLUoMs7pLUIIu7JDXI4i5JDfJSSElqkJdCSlKDbMtIUoMs7pLUIIu7JDXI4i5JDbK4S1KDLO6S1CCLuyQ1yOIuSQ1aP+4XTLIR+HvgSeAzVfWhcW9DknR+Qx25J7k9yekkR5eM70hyIslCkv3d8NuAu6rqBuC6MeeVJA1h2LbMHcCOxQNJ1gG3AjuB7cCeJNuBLcBj3dN+Mp6YkqSVGKotU1X3J5lZMnwNsFBVjwIkuRO4HjjFoMA/wnl+eCTZB+wDuOKKK1aaW2rezP57+45wwT0X/8+TMsoJ1c08fYQOg6K+GfgI8JtJPgDcvdwnV9WBqpqrqrlNmzaNEEOStNTYT6hW1Y+A3x3muUl2AbtmZ2fHHUOSntNGOXJ/HLh80fqWbmxo3vJXkiZjlOL+EHBVkq1JNgC7gcMreQEn65CkyRj2UsiDwAPAtiSnkuytqqeAm4D7gOPAoao6tpKNe+QuSZMx7NUye5YZPwIcWe3G7blL0mQ4zZ4kNch7y0hSg3ot7p5QlaTJSFX1nYEkZ4BvrPLTLwW+O8Y44zSt2aY1F5htNaY1F0xvtmnNBSvL9oqqOudfgU5FcR9Fkvmqmus7x7lMa7ZpzQVmW41pzQXTm21ac8H4stlzl6QGWdwlqUEtFPcDfQc4j2nNNq25wGyrMa25YHqzTWsuGFO2Nd9zlyQ9UwtH7pKkJSzuktSgNV3cl5nD9UJu/xlzyyZ5aZJPJPla9+9LuvEkeX+X9YtJrp5grsuTfDrJl5McS/JH05AtyfOTfDbJF7pc7+3GtyZ5sNv+h7u7jJLkom59oXt8ZhK5lmRcl+TzSe6ZpmxJTib5UpJHksx3Y9Owr12S5K4kX0lyPMlrpyTXtu5rdfbjh0neMyXZ/rjb/48mOdh9X4x/P6uqNfkBrAP+B7gS2AB8Adh+gTO8AbgaOLpo7K+A/d3yfuB93fJbgI8BAV4DPDjBXJcBV3fLLwa+ymCe216zda//om75ecCD3fYOAbu78duAd3fLvw/c1i3vBj58Ad7TPwH+FbinW5+KbMBJ4NIlY9Owr/0z8Hvd8gbgkmnItSTjOuDbwCv6zsZgtrqvAy9YtH+9axL72cS/sBN8w14L3Ldo/Wbg5h5yzPD/i/sJ4LJu+TLgRLf8D8Cecz3vAmT8T+DN05QNeCHwOeDVDP4ab/3S95XB7aRf2y2v756XCWbaAnwS+BXgnu4bfVqyneSZxb3X9xO4uCtUmaZc58j5a8B/T0M2np6e9KXdfnMP8OuT2M/WcltmuTlc+/byqvpWt/xt4OXdci95u1/jXsXgKLn3bF3b4xHgNPAJBr99/aAG8wMs3fbPcnWPPwG8bBK5On8L/Cnw0279ZVOUrYCPJ3k4g8nlof/3cytwBvinrpX1j0k2TkGupXYDB7vlXrNV1ePAXwPfBL7FYL95mAnsZ2u5uE+9Gvy47e1a0yQvAv4deE9V/XDxY31lq6qfVNUrGRwlXwP84oXOcC5J3gqcrqqH+86yjNdX1dXATuAPkrxh8YM9vZ/rGbQlP1BVrwJ+xKDV0Xeun+l619cB/7b0sT6ydT3+6xn8YPwFYCOwYxLbWsvFfeQ5XCfkO0kuA+j+Pd2NX9C8SZ7HoLB/qKo+Mk3ZAKrqB8CnGfwKekmSsxPHLN72z3J1j18MfG9CkV4HXJfkJHAng9bM301JtrNHfFTVaeA/GPxg7Pv9PAWcqqoHu/W7GBT7vnMtthP4XFV9p1vvO9ubgK9X1Zmq+jHwEQb73tj3s7Vc3Eeew3VCDgPv7JbfyaDffXb8d7qz8q8Bnlj06+FYJQnwQeB4Vf3NtGRLsinJJd3yCxicBzjOoMi/fZlcZ/O+HfhUd7Q1dlV1c1VtqaoZBvvSp6rqHdOQLcnGJC8+u8ygh3yUnt/Pqvo28FiSbd3QrwJf7jvXEnt4uiVzNkOf2b4JvCbJC7vv07Nfs/HvZ5M+mTHJDwZnuL/KoG/75z1s/yCDvtmPGRzF7GXQD/sk8DXgv4CXds8NcGuX9UvA3ARzvZ7Br5tfBB7pPt7Sdzbgl4HPd7mOAn/ZjV8JfBZYYPDr80Xd+PO79YXu8Ssv0Pv6Rp6+Wqb3bF2GL3Qfx87u632/n922XgnMd+/pR4GXTEOubnsbGRzlXrxorPdswHuBr3TfA/8CXDSJ/czbD0hSg9ZyW0aStAyLuyQ1yOIuSQ2yuEtSgyzuktQgi7skNcjiLkkN+j9JZDl3adTEnwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(particles_signal_test[:,:,0].flatten())\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_signal_test = normalize_features(particles_signal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'normalized pt')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAARdklEQVR4nO3de6xlZXnH8e9PEIyg2MCYKhcHewCdar30FDVNq1ZrBnDAeMGZSit2wgQspmlj6niNvVg1aZuUFMVpxLGmcpEaO5SxeKlIakAZ8Mal6IhjGS4yguJdQJ/+sRd05zgzZ53Ze589553vJzmZvd+19lrPe/aZ57znWe9eb6oKSVJbHjbtACRJ42dyl6QGmdwlqUEmd0lqkMldkhpkcpekBpncpV1IUklmusfnJXnrmI9/epL/HucxpQftP+0ApKWgqs6cdgzDkrwdmKmq06Ydi/ZOjtzVhCQOVKQhJndNVZJtSV6f5CtJ7k1yUZJHDG0/I8nWJPck2ZTk8UPbKsmfJPk68PUkz0uyPclfJLkryR1JXpLkxCRf647xpqHXH5/kqiTf6/b9pyQH7CLOjUn+pnt8aZIfDn39Isnp3bYnJflkd66bk5w6dIxDuz58P8kXgF/bzfdlede/dUlu7+J7fbdtJfAm4JXd+b+8h99+Nczkrr3BqcBK4GjgN4DTAZL8HvDObvvjgG8BF8557UuAZwEruue/CjwCOBx4G/DPwGnAbwK/A7w1ydHdvj8H/gw4DHgO8ALgtfMFW1WrqurgqjoYeAVwJ/DpJAcBnwQ+DDwWWA28J8mDsZ0L/LTryx93X/N5PnAM8CLgDUleWFX/CfwtcFEXx9N6HEf7GJO79gbnVNXtVXUPcCnw9K79VcD5VXVdVf0MeCPwnCTLh177zqq6p6p+0j2/H3hHVd3P4BfBYcA/VtUPquoG4EbgaQBVdW1VXV1VD1TVNuB9wHP7Bp3kWOCDwKlVdSvwYmBbVX2gO+YXgX8DXpFkP+BlwNuq6kdVdX332vn8Zbf/V4EPAGv6xqd9m3VK7Q3uHHr8Y+DB0svjgese3FBVP0xyN4NR+bau+dY5x7q7qn7ePX4w4X97aPtPgIPhoeT8D8As8EgG/x+u7RNwkkOAfwfeUlUPznh5AvCsJN8b2nV/4EPAsu7xcLzf6nGqufs/tU98kiN37c1uZ5AwAejKHocCtw3tM8ptTd8L/A9wTFU9mkEdO/O9KMnDGJRePlNVG4Y23Qp8tqoeM/R1cFWdBewAHgCOHNr/qB4xzt3/9u6xt3PVbpnctTe7AHhNkqcnOZBBnfnzXQllHB4FfB/4YZInAWf1fN07gIOAP53T/h/AsUn+MMnDu6/fSvLk7q+JjwJvT/LIrg7/6h7nemu3/68DrwEu6tq/DSzvftFIv8QfDO21qupTwFsZ1K3vYDC7ZPUYT/F64A+AHzC48HrR7nd/yBrg2cB3h2bMvKqqfsDgwudqBiPsO4F3Awd2rzubQUnoTmAjgxr6fD4LbAU+DfxdVX2ia/9I9+/dSa7b6Su1T4uLdUh7n+6i8TeBh1fVA1MOR0uQI3dJapDJXZIaZFlGkhrkyF2SGrRXfIjpsMMOq+XLl087DElaUq699trvVNWynW2banJPsgpYNTMzw5YtW6YZiiQtOUl2+SnnqZZlqurSqlp3yCGHTDMMSWrOVJN7klVJNtx7773TDEOSmuPIXZIa5GwZSWqQZRlJapBlGUlqkGUZSWqQZRlJatBUP8RUVZcCl87Ozp6xp8dYvv6yMUa0MNveddLUzi1Ju2NZRpIaZFlGkhrkbBlJapBlGUlqkMldkhpkzV2SGmTNXZIaZFlGkhpkcpekBpncJalBXlCVpAZ5QVWSGmRZRpIaZHKXpAaZ3CWpQSZ3SWqQyV2SGmRyl6QGOc9dkhrkPHdJapBlGUlqkMldkhpkcpekBpncJalBJndJapDJXZIaZHKXpAZNJLknOSjJliQvnsTxJUm71yu5Jzk/yV1Jrp/TvjLJzUm2Jlk/tOkNwMXjDFSS1F/fkftGYOVwQ5L9gHOBE4AVwJokK5L8PnAjcNcY45QkLcD+fXaqqiuTLJ/TfDywtapuAUhyIXAKcDBwEIOE/5Mkm6vqF3OPmWQdsA7gqKOO2uMOSJJ+Wa/kvguHA7cOPd8OPKuqzgZIcjrwnZ0ldoCq2gBsAJidna0R4pAkzTFKct+tqto43z5JVgGrZmZmJhWGJO2TRpktcxtw5NDzI7q23rwrpCRNxijJ/RrgmCRHJzkAWA1sWsgBvJ+7JE1G36mQFwBXAccl2Z5kbVU9AJwNXA7cBFxcVTcs5OSO3CVpMvrOllmzi/bNwOaxRiRJGpnL7ElSg1xmT5Ia5MhdkhrkyF2SGuQtfyWpQSZ3SWqQNXdJapA1d0lqkGUZSWqQyV2SGmTNXZIaZM1dkhpkWUaSGmRyl6QGmdwlqUFeUJWkBnlBVZIaZFlGkhpkcpekBpncJalBJndJapDJXZIa5FRISWqQUyElqUGWZSSpQftPO4ClbPn6y6Zy3m3vOmkq55W0dDhyl6QGmdwlqUEmd0lqkMldkhpkcpekBpncJalBY0/uSZ6c5LwklyQ5a9zHlyTNr1dyT3J+kruSXD+nfWWSm5NsTbIeoKpuqqozgVOB3x5/yJKk+fQduW8EVg43JNkPOBc4AVgBrEmyott2MnAZsHlskUqSeuuV3KvqSuCeOc3HA1ur6paqug+4EDil239TVZ0AvGpXx0yyLsmWJFt27NixZ9FLknZqlNsPHA7cOvR8O/CsJM8DXgocyG5G7lW1AdgAMDs7WyPEIUmaY+z3lqmqK4Ar+uybZBWwamZmZtxhSNI+bZTZMrcBRw49P6Jr681b/krSZIyS3K8BjklydJIDgNXApoUcwMU6JGky+k6FvAC4CjguyfYka6vqAeBs4HLgJuDiqrphISd35C5Jk9Gr5l5Va3bRvpkRpjtac5ekyXCZPUlqkPeWkaQGTTW5e0FVkibDsowkNciyjCQ1yLKMJDXIsowkNciyjCQ1yOQuSQ2y5i5JDbLmLkkNsiwjSQ0yuUtSg0zuktQgk7skNWjsa6guhPdz3zPL1182tXNve9dJUzu3pP6cLSNJDbIsI0kNMrlLUoNM7pLUIJO7JDXI5C5JDfLGYZLUIKdCSlKDLMtIUoNM7pLUIJO7JDXI5C5JDTK5S1KDTO6S1CCTuyQ1aCL3c0/yEuAk4NHA+6vqE5M4jyRp53qP3JOcn+SuJNfPaV+Z5OYkW5OsB6iqj1XVGcCZwCvHG7IkaT4LKctsBFYONyTZDzgXOAFYAaxJsmJol7d02yVJi6h3cq+qK4F75jQfD2ytqluq6j7gQuCUDLwb+HhVXbez4yVZl2RLki07duzY0/glSTsx6gXVw4Fbh55v79peB7wQeHmSM3f2wqraUFWzVTW7bNmyEcOQJA2byAXVqjoHOGe+/Vwge+mZ1uLcLswtLcyoI/fbgCOHnh/RtfXiXSElaTJGTe7XAMckOTrJAcBqYNPoYUmSRrGQqZAXAFcBxyXZnmRtVT0AnA1cDtwEXFxVNyzgmC7WIUkT0LvmXlVrdtG+Gdi8JyevqkuBS2dnZ8/Yk9dLknbOZfYkqUEusydJDfLGYZLUIMsyktQgyzKS1CDLMpLUIMsyktQgyzKS1CDLMpLUIJO7JDXImrskNciauyQ1yLKMJDXI5C5JDTK5S1KDvKAqSQ3ygqokNciyjCQ1yOQuSQ3qvYaqNE3L1182lfNue9dJUzmvNCpH7pLUIJO7JDXI5C5JDXKeuyQ1yHnuktQgyzKS1CCTuyQ1yOQuSQ0yuUtSg0zuktQgk7skNcjkLkkNGntyT/LEJO9Pcsm4jy1J6qdXck9yfpK7klw/p31lkpuTbE2yHqCqbqmqtZMIVpLUT9+R+0Zg5XBDkv2Ac4ETgBXAmiQrxhqdJGmP9EruVXUlcM+c5uOBrd1I/T7gQuCUvidOsi7JliRbduzY0TtgSdL8Rqm5Hw7cOvR8O3B4kkOTnAc8I8kbd/XiqtpQVbNVNbts2bIRwpAkzTX2lZiq6m7gzD77JlkFrJqZmRl3GNJYTGsFKHAVKI1mlJH7bcCRQ8+P6Np6866QkjQZoyT3a4Bjkhyd5ABgNbBpIQfwfu6SNBl9p0JeAFwFHJdke5K1VfUAcDZwOXATcHFV3bCQkztyl6TJ6FVzr6o1u2jfDGwea0SSpJGN/YLqQnhBVdr7eBG5DS6zJ0kNcoFsSWqQI3dJapC3/JWkBpncJalB1twlqUHW3CWpQZZlJKlBJndJapCfUJW0z2vxU7nW3CWpQZZlJKlBJndJapDJXZIa5IeYJKlBXlCVpAZZlpGkBpncJalBJndJapDJXZIaZHKXpAY5FVKSGuRUSElqkGUZSWqQyV2SGmRyl6QGmdwlqUEmd0lqkMldkhpkcpekBpncJalB+4/7gEkOAt4D3AdcUVX/Ou5zSJJ2r9fIPcn5Se5Kcv2c9pVJbk6yNcn6rvmlwCVVdQZw8pjjlST10LcssxFYOdyQZD/gXOAEYAWwJskK4Ajg1m63n48nTEnSQvQqy1TVlUmWz2k+HthaVbcAJLkQOAXYziDBf4nd/PJIsg5YB3DUUUctNG6pecvXXzbtEBbdvtjnSRnlgurh/P8IHQZJ/XDgo8DLkrwXuHRXL66qDVU1W1Wzy5YtGyEMSdJcY7+gWlU/Al7TZ98kq4BVMzMz4w5DkvZpo4zcbwOOHHp+RNfWm7f8laTJGCW5XwMck+ToJAcAq4FNCzmAi3VI0mT0nQp5AXAVcFyS7UnWVtUDwNnA5cBNwMVVdcNCTu7IXZImo+9smTW7aN8MbN7Tk1tzl6TJcJk9SWqQ95aRpAZNNbl7QVWSJiNVNe0YSLID+NYevvww4DtjDGcpsM/7Bvu8bxilz0+oqp1+CnSvSO6jSLKlqmanHcdiss/7Bvu8b5hUn625S1KDTO6S1KAWkvuGaQcwBfZ532Cf9w0T6fOSr7lLkn5ZCyN3SdIcJndJatCSSe67WK91ePuBSS7qtn9+JytHLTk9+vznSW5M8pUkn07yhGnEOU7z9Xlov5clqSRLftpcnz4nObV7r29I8uHFjnHcevxsH5XkM0m+2P18nziNOMdlV+tQD21PknO678dXkjxz5JNW1V7/BewHfAN4InAA8GVgxZx9Xguc1z1eDVw07bgXoc/PBx7ZPT5rX+hzt9+jgCuBq4HZace9CO/zMcAXgV/pnj922nEvQp83AGd1j1cA26Yd94h9/l3gmcD1u9h+IvBxIMCzgc+Pes6lMnJ/aL3WqroPeHC91mGnAB/sHl8CvCBJFjHGcZu3z1X1mar6cff0agYLpixlfd5ngL8G3g38dDGDm5A+fT4DOLeqvgtQVXctcozj1qfPBTy6e3wIcPsixjd2VXUlcM9udjkF+JcauBp4TJLHjXLOpZLcd7Ve6073qcG95u8FDl2U6CajT5+HrWXwm38pm7fP3Z+rR1ZVKysp93mfjwWOTfK5JFcnWblo0U1Gnz6/HTgtyXYGtxV/3eKENjUL/f8+r7GvoarFl+Q0YBZ47rRjmaQkDwP+ATh9yqEstv0ZlGaex+CvsyuTPLWqvjfNoCZsDbCxqv4+yXOADyV5SlX9YtqBLRVLZeTeZ73Wh/ZJsj+DP+XuXpToJqPXGrVJXgi8GTi5qn62SLFNynx9fhTwFOCKJNsY1CY3LfGLqn3e5+3Apqq6v6q+CXyNQbJfqvr0eS1wMUBVXQU8gsENtlo18prUcy2V5N5nvdZNwKu7xy8H/qu6KxVL1Lx9TvIM4H0MEvtSr8PCPH2uqnur6rCqWl5VyxlcZzi5qrZMJ9yx6POz/TEGo3aSHMagTHPLIsY4bn36/L/ACwCSPJlBct+xqFEurk3AH3WzZp4N3FtVd4x0xGlfRV7A1eYTGYxYvgG8uWv7Kwb/uWHw5n8E2Ap8AXjitGNehD5/Cvg28KXua9O0Y550n+fsewVLfLZMz/c5DMpRNwJfBVZPO+ZF6PMK4HMMZtJ8CXjRtGMesb8XAHcA9zP4S2wtcCZw5tB7fG73/fjqOH6uvf2AJDVoqZRlJEkLYHKXpAaZ3CWpQSZ3SWqQyV2SGmRyl6QGmdwlqUH/Bwxpa0B77TTNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(particles_signal_test[:,:,0].flatten())\n",
    "plt.yscale('log')\n",
    "plt.title('normalized pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_signal, A_pred_probs_signal = gnn((particles_signal_test, A_tilde_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pred_signal = (A_pred_probs_signal > 0.5).numpy().astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_signal = gnn.test_step(((particles_signal_test, A_tilde_signal), A_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.64076227>}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
